# Road-extraction
Semi supervised Approach to extract road maps from aerial images using Generative adversarial networks in keras.


## Abstract
Road extraction from aerial image, stands as a quintessential node for the development of rudimentary layers in innumerable fields. From GIS, to Unmanned Aerial vehicles, road maps pave the foundation for data accumulation. This significant process is a result of number of mechanisms devised over the years through iterative experiments and research.  However, the glut of methods available often pose as a hurdle in the selection process. In this project we implement a novel approach to solve the extraction problem, by incorporating generative algorithm using conditional adversarial networks. We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. The U-Network incorporated essentially convolves and de-convolves over the generative model, thus producing a pixel to pixel image translation, the result of which is the vector road map of its corresponding aerial image. The entire model is trained on a 990 MS GPU for computational ease.  

## Introduction
Image processing and Computer vision have evolved over the years to account for nuances in the pragmatic world, and extend a visual cortex to technology. This development
has been a boon to aerial images. With advances such as segmentation,
pruning,Principal Component Analysis (PCA), and self- learning artificial intelligence
implementations such as Artificial Neural Networks (ANN), Suppport Vector Machine
(SVM), and classification, quality of image data sets have surged immensely. However,
the paramount notion that these advancements are based on unique circumstances, and
that their efficiency relates to the appropriate usage , has now vaporized into the obsolete.
In order to discern the perfect extraction mechanism, it is essential that the details
of land image data set and their context is understood as a base.
This project proposes road extraction from remotely sensed data using a novel generative
approach with a Generative Adversarial Network (GAN) model. The form of
learning differs from discriminative/ predictive algorithm by aiming for image- image
translation Instead of predicting a label given certain features, GANs attempt to predict
features given a certain label..

## Generative Adversarial Networks
Created and introduced by Dr. Ian Goodfellow along with professor Yoshua Bengio at
the university of Montreal, Generative adversarial networks (GANs) are regarded as the
panacea for all deep learning image translation problems. These advanced, generalized
large goal oriented deep learning networks were created in 2014 . GANs essentially
consist of two networks namely: the generator which generates fake images, or the
required output image, and the discriminator network is its adversary, which checks
if the images/outputs generated by the generator are authentic or not. These two networks
compete against each other; thus, the combined module is called a generative
adversarial network.

Generative algorithms work in opposing sides from the discriminative algorithm.
The latter tries to classify input data; that is, given the features of a data instance, they
predict a label or category to which that data belongs.

Concretely, a discriminative algorithm tries to find a label for a set of features. A simple
classification of email as spam or not is done with the formulation that probability
of email as spam is given with consideration of the words it contains. Mathematically
represented as p(y|x), discriminative algorithms translate features into labels. They are
concerned solely with that correlation. Generative algorithms on the other hand do the
opposite. Instead of predicting the class a set of features belong into, the generative
algorithms find probability of features given the class it belongs in. Mathematically it
can be viewed as p(x|y). Where, given the class of spam, the spam classifier tries to find
the words that cause its spam labelling. Another way to think about it is to distinguish
discriminative from generative like this: Discriminative models learn the boundary between
classes; Generative models model the distribution of individual classes.

### Working
Generative adversarial networks work in a cyclic manner where, the generator tries to
create fake images, and the discriminator tries to discriminate the real images from the
fake ones. The entire working can be thought of as a game of cop and counterfeiter. The
counterfeiter tries to create fake images (i.e the generator tries to create fake images),
and the duty of the cop, is to identity the fake images from the lot. This way, through the
generation process, the counterfeiter becomes an expert with experience, and so does
the cop.

In a module such as this, the final image ends up being inevitably similar to the training
dataset. This is how GAN solves the problems that arise out of a smaller goal. The goal
often render to a GAN is on a larger scale. In contrast to a stand-alone CNN module,
the GAN is given a larger goal requesting lookalike image copies. Such large goals,
work their way towards the ultimate output that we desire, non-blurry crisp vector road
maps.
On a holistic view, GAN used to rectify blurred images, is trained
by providing a noisier version of an image to a generator. The generator generates an
image, which is expected to be the reconstructed, clear output. This image is then fed to
a discriminator along with the original clear version of the image. Now the discrimina-
21
tor tries to classify the current output from generator as fake or real. Using this result,
the model is further trained.


Working of GAN model:
* The generator takes in aerial images and returns a random (to be road map) image.
* This generated image is fed into the discriminator alongside a stream of (actual
road map) images taken from the actual dataset.
* The discriminator takes in both real and fake images and returns probabilities, a
number between 0 and 1, with 1 representing a prediction of authenticity and 0
representing fake
* The value is fed as feedback to generator and discriminator. A both the networks
trains with respect to the requirement. i.e Generator trains to generate road maps,
and D tried to identify fake road maps.
* Both the networks continue to train till the number of epochs exhaust.
22


## Conditional Adversarial Networks
When the noise input to the generator is replaced with a completely different image,
requesting for a generation of its mapped output, the model is named as conditional
adversarial network. The entirety of working remains the same, however, Pz(z) now
represents a whole new image, and G(z) is now its vector road map.

### Formulation
Conditional Adversarial Network (CGAN) typically utilize the probability distributions
where the following are regarded as the standards.

Pdata(x) : Distribution of data (vector road maps)

X : A sample from the distribution of data

Pz(z) :A new image, given to a generator( Aerial images)

Z : A sample from the distribution new images

G(z) :Generator Network

D(x) :Discriminator Network

The training occurs as a one on one match against the two networks. The generator
tries to minimize, whereas the discriminator tries to maximize the function V.
The first term forms the entropy of data for the discriminator, Pdata(x). It aims to
maximise the value of output to 1.
The second term forms the entropy of aerial images Pz(z) that the generator generates.
Here, the discriminator aims to maximise the value of output to 0. In other words, the
generator tries to generate output such that the log probability of its generated outputs
deemed as fake, is 0.
Thus, they train over an iterative approach, pitting against each other, where G tries
to minimize, and D tries to maximize.


### Algorithm
Using mini batch stochastic gradient descent over 25000 iterations, and batch size as 1,
the following steps are carried out:

he alternate steps of training Generator and Discriminator converge at one point
4.2.3 

### Advantages of conditional AN
* CGANs learn a structured loss. Structured losses penalize the joint configuration
of the output. Our conditional GAN is different in that the loss is learned, and can,
in theory, penalize any possible structure that differs between output and target.
* Our framework differs in that nothing is application-specific. This makes our
setup considerably simpler than most others.
* Significantly faster, and computationally convenient

* Larger, meaningful goal for easier implementation
* Reduced computational complexity
* Can utilize full efficiency of batch- normalization
* Can extract features which are microscopic in the image, i.e invisible to the naked
eye in an aerial image.
* No blur images are generated


# SYSTEM ARCHITECTURE AND DESIGN

## Generator Architecture
The generator architecture typically follows a U- Network. U- Network consists of
convolutions followed by de-convolutions. The number of layers involved in the U-net
are 28 including the input and output.

U-Network architecture used for the generator


## Discriminator Architecture
Termed as a Patch-GAN module, the discriminator is created a patch identifier. The
discriminator is made up of an inbuilt convolutional network, which classifies if each
patch of NxN pixels in an image belongs to the fake class or real. Averaging the output
finally produces the output of the discriminator. The smaller size of the filer helps
increase computational time, while producing better quality images.



# Dataset Specifications
* The dataset was obtained from University of Toronto's website.
* Named: Road and Building dataset
* The dataset contains aerial images of Massachusetts road
* The entire dataset contains aerial images and their corresponding target vector
road maps.
* Aerial images were originally of 1500* 1500 *3 pixels of the format TIFF as
shown
* Corresponding road maps of 1500*1500*1 of the format TIF as shown in Fig 16.
* Train images: 1108 input and target, Test images: 29 input and target, Validation
images: 14 input and target
* Dataset modified for experiment: 105 * 105 * 3 for aerial images in JPEG format,
105*105*1 for road maps in JPEG format.


Figure Sample Aerial Image

Figure Corresponding Vector Road Map


# Tools Used
* Module used:
– PYTHON 3.6
– Jupyter Notebook 4.3
– Anaconda 5.1
* Packages:
– Keras with Tensorflow-gpu as backend
– Matplotlib
– Numpy
– Scipy
* Hardware requirements: 990 ms GPU
* Optimization parameters: Alternate between one gradient descent step on D, then
one step on G.
* Minibatch SGD and apply the Adam solver
